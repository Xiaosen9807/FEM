{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import atan\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import lagrange\n",
    "from scipy.misc import derivative\n",
    "\n",
    "from sympy import symbols, integrate, sinh, E, diff\n",
    "import sympy as sp\n",
    "from scipy.special import roots_legendre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0378828427399902\n"
     ]
    }
   ],
   "source": [
    "x = symbols('x')\n",
    "u = -2*E/(E**2 - 1)*sinh(x) + x\n",
    "print(integrate(u, (x, 0, 1)).evalf())\n",
    "un = 0.14588*x*(1-x) + 0.16279*x**2*(1-x)\n",
    "du = diff(u, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange(x, y, num_points, x_test):\n",
    "    # 所有的基函数值，每个元素代表一个基函数的值\n",
    "    l = np.zeros(shape=(num_points, ))\n",
    "\n",
    "    # 计算第k个基函数的值\n",
    "    for k in range(num_points):\n",
    "        # 乘法时必须先有一个值\n",
    "        # 由于l[k]肯定会被至少乘n次，所以可以取1\n",
    "        l[k] = 1\n",
    "        # 计算第k个基函数中第k_个项（每一项：分子除以分母）\n",
    "        for k_ in range(num_points):\n",
    "            # 这里没搞清楚，书中公式上没有对k=k_时，即分母为0进行说明\n",
    "            # 有些资料上显示k是不等于k_的\n",
    "            if k != k_:\n",
    "                # 基函数需要通过连乘得到\n",
    "                l[k] = l[k]*(x_test-x[k_])/(x[k]-x[k_])\n",
    "            else:\n",
    "                pass\n",
    "    # 计算当前需要预测的x_test对应的y_test值\n",
    "    L = 0\n",
    "    for i in range(num_points):\n",
    "        # 求所有基函数值的和\n",
    "        L += y[i]*l[i]\n",
    "    return L\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    # x.grad.zero_()\n",
    "    constant = a*xb+torch.zeros_like(x)\n",
    "    dy = (1 - x) * (atan(a * (x - xb)) +\n",
    "                    atan(constant))\n",
    "    return dy\n",
    "    \n",
    "\n",
    "\n",
    "def G_integrate(u, x, N=3):\n",
    "    N = N  # 取3个样本点\n",
    "    a = x.min()  # 积分上下限\n",
    "    b = x.max()\n",
    "    x, w = roots_legendre(N)\n",
    "    #print(x)\n",
    "    x = torch.Tensor(x)\n",
    "    w = torch.Tensor(w)\n",
    "\n",
    "    xp = x*(b-a)/2+(b+a)/2\n",
    "    wp = w*(b-a)/2\n",
    "\n",
    "    s = 0\n",
    "    for i in range(N):\n",
    "        s += wp[i]*u(x=xp[i])\n",
    "    return s\n",
    "\n",
    "\n",
    "def error(u, uh):\n",
    "    du = diff(u, x)\n",
    "    B = integrate((du**2+u**2), (x, 0, 1))\n",
    "    A = (1/2*B)**0.5\n",
    "    dut = diff(un-u, x)\n",
    "    Bt = integrate((dut**2+(un-u)**2), (x, 0, 1))\n",
    "    At = (1/2*Bt)**0.5\n",
    "    return float(At.evalf()/A.evalf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0769, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.linspace(0, 1, 5, requires_grad=True)\n",
    "\n",
    "a = 0.5\n",
    "xb = 0.8\n",
    "print(G_integrate(f, x))\n",
    "\n",
    "def error(u, uh, x=x):\n",
    "    dudx = grad(u, x,\n",
    "                grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "                create_graph=True,\n",
    "                retain_graph=True)  # 为计算二阶导保持计算图\n",
    "    B = G_integrate((dudx**2+u**2), x)\n",
    "    A = (1/2*B)**0.5\n",
    "    dut = diff(un-u, x)\n",
    "    Bt = integrate((dut**2+(un-u)**2), (x, 0, 1))\n",
    "    At = (1/2*Bt)**0.5\n",
    "    return float(At.evalf()/A.evalf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dydx tensor([ 0.0312,  0.0382,  0.0690,  1.3686, -3.0169], grad_fn=<AddBackward0>)\n",
      "dzdx tensor([ 0.0625,  0.0763,  0.1381,  2.7373, -6.0339], grad_fn=<AddBackward0>)\n",
      "d2ydx2 (tensor([ 1.5566e-02,  4.7783e-02,  2.9172e-01,  4.5660e+01, -9.9010e-01],\n",
      "       grad_fn=<AddBackward0>),)\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 5, requires_grad=True)\n",
    "a = 50\n",
    "xb = 0.8\n",
    "\n",
    "y = f(x)\n",
    "z = 2*f(x)\n",
    "#f(x, a, xb)\n",
    "# print(y)\n",
    "# dy.backward()\n",
    "# plt.plot(x.grad)\n",
    "dydx = grad(y, x,\n",
    "            grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "            create_graph=True,\n",
    "            retain_graph=True)  # 为计算二阶导保持计算图\n",
    "dzdx = grad(z, x,\n",
    "            grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "            create_graph=True,\n",
    "            retain_graph=True)  # 为计算二阶导保持计算图\n",
    "print('dydx', dydx[0])\n",
    "print('dzdx', dzdx[0])\n",
    "d2ydx2 = grad(dydx[0], x,\n",
    "            grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "            create_graph=True,\n",
    "            retain_graph=True)  # 为计算二阶导保持计算图\n",
    "print('d2ydx2', d2ydx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.3750, 1.7500, 2.1250, 2.5000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 5, requires_grad=True)\n",
    "xp = x*(1+2)/2+1\n",
    "xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f() got an unexpected keyword argument 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/qinxusen/Desktop/FEM/Question1.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qinxusen/Desktop/FEM/Question1.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qinxusen/Desktop/FEM/Question1.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xp \u001b[39m=\u001b[39m x\u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m+\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qinxusen/Desktop/FEM/Question1.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(G_integrate(f(x, a\u001b[39m=\u001b[39;49ma, xb\u001b[39m=\u001b[39;49mxb), x, scale\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: f() got an unexpected keyword argument 'a'"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 5, requires_grad=True)\n",
    "xp = x*(1-2)/2+(1+1)/2\n",
    "print(G_integrate(f(x, a=a, xb=xb), x, scale=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dydx tensor([ 0.0312,  0.0314,  0.0316,  0.0317,  0.0319,  0.0321,  0.0323,  0.0325,\n",
      "         0.0327,  0.0329,  0.0332,  0.0334,  0.0337,  0.0339,  0.0342,  0.0345,\n",
      "         0.0348,  0.0351,  0.0354,  0.0358,  0.0361,  0.0365,  0.0369,  0.0374,\n",
      "         0.0378,  0.0383,  0.0388,  0.0393,  0.0399,  0.0405,  0.0411,  0.0418,\n",
      "         0.0425,  0.0433,  0.0441,  0.0450,  0.0459,  0.0469,  0.0480,  0.0491,\n",
      "         0.0504,  0.0517,  0.0531,  0.0547,  0.0564,  0.0583,  0.0603,  0.0625,\n",
      "         0.0649,  0.0676,  0.0706,  0.0738,  0.0774,  0.0815,  0.0860,  0.0911,\n",
      "         0.0969,  0.1034,  0.1109,  0.1195,  0.1295,  0.1411,  0.1548,  0.1710,\n",
      "         0.1904,  0.2139,  0.2429,  0.2789,  0.3245,  0.3835,  0.4614,  0.5672,\n",
      "         0.7154,  0.9312,  1.2600,  1.7885,  2.6869,  4.2646,  6.7559,  8.5539,\n",
      "         6.3195,  2.6938,  0.3611, -0.9108, -1.6237, -2.0496, -2.3201, -2.5011,\n",
      "        -2.6276, -2.7192, -2.7875, -2.8397, -2.8805, -2.9130, -2.9392, -2.9607,\n",
      "        -2.9785, -2.9935, -3.0061, -3.0169], grad_fn=<AddBackward0>)\n",
      "d2ydx2 (tensor([ 1.5566e-02,  1.6170e-02,  1.6806e-02,  1.7475e-02,  1.8180e-02,\n",
      "         1.8924e-02,  1.9708e-02,  2.0537e-02,  2.1413e-02,  2.2339e-02,\n",
      "         2.3320e-02,  2.4358e-02,  2.5460e-02,  2.6628e-02,  2.7870e-02,\n",
      "         2.9189e-02,  3.0594e-02,  3.2089e-02,  3.3684e-02,  3.5386e-02,\n",
      "         3.7205e-02,  3.9151e-02,  4.1235e-02,  4.3469e-02,  4.5867e-02,\n",
      "         4.8445e-02,  5.1220e-02,  5.4211e-02,  5.7439e-02,  6.0928e-02,\n",
      "         6.4706e-02,  6.8802e-02,  7.3252e-02,  7.8093e-02,  8.3370e-02,\n",
      "         8.9133e-02,  9.5439e-02,  1.0235e-01,  1.0995e-01,  1.1832e-01,\n",
      "         1.2756e-01,  1.3779e-01,  1.4914e-01,  1.6177e-01,  1.7586e-01,\n",
      "         1.9164e-01,  2.0936e-01,  2.2934e-01,  2.5193e-01,  2.7758e-01,\n",
      "         3.0684e-01,  3.4034e-01,  3.7890e-01,  4.2350e-01,  4.7536e-01,\n",
      "         5.3603e-01,  6.0744e-01,  6.9209e-01,  7.9318e-01,  9.1487e-01,\n",
      "         1.0627e+00,  1.2440e+00,  1.4687e+00,  1.7508e+00,  2.1094e+00,\n",
      "         2.5722e+00,  3.1797e+00,  3.9923e+00,  5.1035e+00,  6.6612e+00,\n",
      "         8.9095e+00,  1.2266e+01,  1.7481e+01,  2.5964e+01,  4.0507e+01,\n",
      "         6.6828e+01,  1.1621e+02,  2.0249e+02,  2.7069e+02,  9.8874e-01,\n",
      "        -3.7249e+02, -3.0249e+02, -1.6826e+02, -9.2061e+01, -5.3375e+01,\n",
      "        -3.3002e+01, -2.1590e+01, -1.4803e+01, -1.0552e+01, -7.7670e+00,\n",
      "        -5.8735e+00, -4.5442e+00, -3.5850e+00, -2.8764e+00, -2.3419e+00,\n",
      "        -1.9315e+00, -1.6113e+00, -1.3579e+00, -1.1548e+00, -9.9010e-01],\n",
      "       grad_fn=<AddBackward0>),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17d0c7280>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 100, requires_grad=True)\n",
    "a = 50\n",
    "xb = 0.8\n",
    "\n",
    "y = f(x, a, xb)\n",
    "#f(x, a, xb)\n",
    "# print(y)\n",
    "# dy.backward()\n",
    "# plt.plot(x.grad)\n",
    "dydx = grad(y, x,\n",
    "            grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "            create_graph=True,\n",
    "            retain_graph=True)  # 为计算二阶导保持计算图\n",
    "print('dydx', dydx[0])\n",
    "d2ydx2 = grad(dydx[0], x,\n",
    "            grad_outputs=torch.ones(x.shape),  # 注意这里需要人为指定\n",
    "            create_graph=True,\n",
    "            retain_graph=True)  # 为计算二阶导保持计算图\n",
    "print('d2ydx2', d2ydx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0156, 0.1250, 0.4219, 1.0000], grad_fn=<PowBackward0>)\n",
      "(tensor([0.0000, 0.1875, 0.7500, 1.6875, 3.0000], grad_fn=<MulBackward0>),)\n",
      "tensor([0.0000, 0.1875, 0.7500, 1.6875, 3.0000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 28 08:59:50 2020\n",
    "\n",
    "@author: 周文青\n",
    "\n",
    "利用torch.autograd计算单变量标量函数y=x^3+sin(x)在x分别为1，pi和5时的一阶导数和二\n",
    "阶导数\n",
    "\n",
    "\"\"\"\n",
    "import torch as tc\n",
    "import numpy as np\n",
    "\n",
    "# %% 方法1：采用torch.autograd.grad\n",
    "x = tc.linspace(0, 1, 5, requires_grad=True)\n",
    "y = x**3\n",
    "print(y)\n",
    "dy = 3*x**2\n",
    "d2y = 6*x\n",
    "\n",
    "dydx = tc.autograd.grad(y, x,\n",
    "                        grad_outputs=tc.ones(x.shape),  # 注意这里需要人为指定\n",
    "                        create_graph=True,\n",
    "                        retain_graph=True)  # 为计算二阶导保持计算图\n",
    "print(dydx)  # 注意输出是一个tuple，取第一个元素\n",
    "# (tensor([ 3.5403, 28.6088, 75.2837], grad_fn=<AddBackward0>),)\n",
    "print(dy)\n",
    "# tensor([ 3.5403, 28.6088, 75.2837], grad_fn=<AddBackward0>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,\n",
      "         0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,  0.0003,\n",
      "         0.0003,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n",
      "         0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,  0.0004,\n",
      "         0.0004,  0.0004,  0.0004,  0.0004,  0.0005,  0.0005,  0.0005,  0.0005,\n",
      "         0.0005,  0.0005,  0.0005,  0.0005,  0.0006,  0.0006,  0.0006,  0.0006,\n",
      "         0.0006,  0.0007,  0.0007,  0.0007,  0.0008,  0.0008,  0.0009,  0.0009,\n",
      "         0.0010,  0.0010,  0.0011,  0.0012,  0.0013,  0.0014,  0.0015,  0.0017,\n",
      "         0.0019,  0.0021,  0.0024,  0.0028,  0.0032,  0.0038,  0.0046,  0.0057,\n",
      "         0.0072,  0.0093,  0.0126,  0.0179,  0.0269,  0.0426,  0.0676,  0.0855,\n",
      "         0.0632,  0.0269,  0.0036, -0.0091, -0.0162, -0.0205, -0.0232, -0.0250,\n",
      "        -0.0263, -0.0272, -0.0279, -0.0284, -0.0288, -0.0291, -0.0294, -0.0296,\n",
      "        -0.0298, -0.0299, -0.0301, -0.0302])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u = f(x, a, xb)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('comp2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08a0b207c3eba0a5bb4cbf2f03f6a5ddbcc34f1a6505e46237e72614b95fc4ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
